{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a5a123-c5e6-44da-b25a-755d59e49813",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example) 마케팅 문구 검증 & 교정 Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437e9fc-0c95-4dcd-961d-90b5d99c0310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", \n",
    "                 temperature=0.7)\n",
    "\n",
    "# style check prompt\n",
    "style_check_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    다음 문장이 우리 Writing Style에 맞는지 검토해 주세요. \n",
    "    Writing Style: \"간결하고 설득력 있는 문장을 사용하며, 친근한 톤을 유지합니다.\"\n",
    "\n",
    "    사용자 문장: \"{user_text}\"\n",
    "\n",
    "    결과:\n",
    "    1. Writing Style과 얼마나 부합하는지 (0-100 점수)\n",
    "    2. 어색한 표현이나 개선이 필요한 부분 설명\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# rewrite prompt\n",
    "rewrite_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    다음 문장을 사람들이 더 잘 반응할 수 있도록 개선해 주세요. \n",
    "    Writing Style을 유지하면서 더 매력적인 문장을 만들어야 합니다.\n",
    "\n",
    "    원래 문장: \"{user_text}\"\n",
    "\n",
    "    개선된 문장:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# LCEL 체인\n",
    "style_check_chain = style_check_prompt | llm | StrOutputParser()\n",
    "rewrite_chain = rewrite_prompt | llm | StrOutputParser()\n",
    "\n",
    "full_chain = (\n",
    "    RunnablePassthrough()\n",
    "    .assign(style_feedback=style_check_chain)  # Writing Style 검수\n",
    "    .assign(improved_text=lambda data: rewrite_chain.invoke({\"user_text\": data[\"user_text\"]}))  # 문장 개선\n",
    ")\n",
    "\n",
    "# 실행 함수\n",
    "def review_and_rewrite_text(user_text):\n",
    "    result = full_chain.invoke({\"user_text\": user_text})  # LCEL 체인 실행\n",
    "\n",
    "    print(\"Writing Style 검토 결과:\")\n",
    "    print(result[\"style_feedback\"])\n",
    "\n",
    "    print(\"개선된 문장:\")\n",
    "    print(result[\"improved_text\"])\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 사용자 입력 받기\n",
    "user_text = input(\"✍ 문장을 입력하세요: \")\n",
    "result = review_and_rewrite_text(user_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd570f-84fd-4ca3-b0c2-f30c519e812c",
   "metadata": {},
   "source": [
    "## Logging & Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a8eefe-23d1-4d48-b0ad-027061bc93ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "✍ 문장을 입력하세요:  복주머니 선물할 때마다 최대 1천원씩 보상금 받아요\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LLM에 전달될 프롬프트:\n",
      " 문장을 고쳐 주세요: 복주머니 선물할 때마다 최대 1천원씩 보상금 받아요\n",
      "\n",
      " LLM 응답이 로그에 저장되었습니다.\n",
      "\n",
      " 최종 변환된 결과:\n",
      " 복주머니를 선물할 때마다 최대 1,000원의 보상금을 받아요.\n",
      "\n",
      " 최종 결과 (사용 가능): {'transformed_text': '복주머니를 선물할 때마다 최대 1,000원의 보상금을 받아요.'}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 로깅 설정\n",
    "logging.basicConfig(filename=\"llm_logs.txt\", level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "\n",
    "# 2. LLM 모델 설정\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.7)\n",
    "\n",
    "# 3. 프롬프트 설정\n",
    "#prompt = ChatPromptTemplate.from_template(\"문장을 고쳐 주세요: {user_text}\")\n",
    "prompt = PromptTemplate(\n",
    "    template=\"문장을 고쳐 주세요: {user_text}\",\n",
    "    input_variables=[\"user_text\"]\n",
    ")\n",
    "\n",
    "# 4. LLM 체인 구성\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 5. LLM 호출 전 프롬프트 확인 함수\n",
    "def debug_prompt(data, prompt):\n",
    "    formatted_prompt = prompt.format(user_text=data[\"user_text\"])\n",
    "    print(\"\\n LLM에 전달될 프롬프트:\\n\", formatted_prompt)\n",
    "    return data  # 그대로 반환\n",
    "\n",
    "# 6. LLM 응답을 로깅하는 함수\n",
    "def log_response(data):\n",
    "    response = data[\"response\"]\n",
    "    logging.info(f\"LLM 응답: {response}\")\n",
    "    print(\"\\n LLM 응답이 로그에 저장되었습니다.\")\n",
    "    return data  # 그대로 반환\n",
    "\n",
    "# 7. 최종 결과를 커스텀 변환하는 함수 (예: 대문자로 변환)\n",
    "def transform_output(data):\n",
    "    transformed_text = data[\"response\"].upper()  # 대문자로 변환\n",
    "    print(\"\\n 최종 변환된 결과:\\n\", transformed_text)\n",
    "    return {\"transformed_text\": transformed_text}  # 변환된 결과 반환\n",
    "\n",
    "# 8. LCEL 체인 구성\n",
    "full_chain = (\n",
    "    RunnableLambda(lambda data : debug_prompt(data, prompt))  # LLM 호출 전 프롬프트 확인\n",
    "    .assign(response=chain)  # LLM 실행 후 응답 저장\n",
    "    .assign(log=RunnableLambda(log_response))  # LLM 응답을 로깅\n",
    "    .assign(final_result=RunnableLambda(transform_output))  # 최종 결과 변환\n",
    ")\n",
    "\n",
    "# 9. 실행 함수\n",
    "def process_text(user_text):\n",
    "    result = full_chain.invoke({\"user_text\": user_text})  # LCEL 체인 실행\n",
    "    print(\"\\n 최종 결과 (사용 가능):\", result[\"final_result\"])\n",
    "    return result\n",
    "\n",
    "# 10. 사용자 입력 받기\n",
    "user_text = input(\"✍ 문장을 입력하세요: \")\n",
    "result = process_text(user_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70d4d63d-f86d-4138-b1c9-77d9741206d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_text': '복주머니 선물할 때마다 최대 1천원씩 보상금 받아요',\n",
       " 'response': '복주머니를 선물할 때마다 최대 1,000원의 보상금을 받아요.',\n",
       " 'log': {'user_text': '복주머니 선물할 때마다 최대 1천원씩 보상금 받아요',\n",
       "  'response': '복주머니를 선물할 때마다 최대 1,000원의 보상금을 받아요.'},\n",
       " 'final_result': {'transformed_text': '복주머니를 선물할 때마다 최대 1,000원의 보상금을 받아요.'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
